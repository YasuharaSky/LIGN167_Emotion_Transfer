{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepare_emotion_dataset(csv_path):\n",
    "    \"\"\"\n",
    "    Prepare emotion dataset from CSV file with intensity information.\n",
    "    CSV should have columns: scenario, text, emotion, intensity\n",
    "    Returns data formatted for emotion control training\n",
    "    \"\"\"\n",
    "    # Read CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Dictionary to store formatted data\n",
    "    formatted_data = {}\n",
    "    \n",
    "    # Process each emotion\n",
    "    for emotion in df['emotion'].unique():\n",
    "        # Get data for this emotion\n",
    "        emotion_data = df[df['emotion'] == emotion].copy()\n",
    "        \n",
    "        # Sort by intensity to maintain ordinal relationship\n",
    "        emotion_data = emotion_data.sort_values('intensity')\n",
    "        \n",
    "        # Split into train and test\n",
    "        train_data, test_data = train_test_split(\n",
    "            emotion_data,\n",
    "            test_size=0.2,\n",
    "            random_state=42,\n",
    "            stratify=emotion_data['intensity']  # Maintain intensity distribution\n",
    "        )\n",
    "        \n",
    "        # Store in required format\n",
    "        formatted_data[emotion] = {\n",
    "            'train': {\n",
    "                'data': train_data['text'].tolist(),\n",
    "                'scenarios': train_data['scenario'].tolist(),\n",
    "                'intensities': train_data['intensity'].tolist()\n",
    "            },\n",
    "            'test': {\n",
    "                'data': test_data['text'].tolist(),\n",
    "                'scenarios': test_data['scenario'].tolist(),\n",
    "                'intensities': test_data['intensity'].tolist()\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return formatted_data\n",
    "\n",
    "# def analyze_emotion_distribution(formatted_data):\n",
    "#     \"\"\"\n",
    "#     Print statistics about the dataset including intensity distribution\n",
    "#     \"\"\"\n",
    "#     print(\"Dataset Statistics:\")\n",
    "#     for emotion in formatted_data:\n",
    "#         train_size = len(formatted_data[emotion]['train']['data'])\n",
    "#         test_size = len(formatted_data[emotion]['test']['data'])\n",
    "        \n",
    "#         # Get intensity statistics\n",
    "#         train_intensities = formatted_data[emotion]['train']['intensities']\n",
    "        \n",
    "#         print(f\"\\n{emotion}:\")\n",
    "#         print(f\"  Train samples: {train_size}\")\n",
    "#         print(f\"  Test samples: {test_size}\")\n",
    "#         print(f\"  Intensity distribution (train):\")\n",
    "#         for intensity in sorted(set(train_intensities)):\n",
    "#             count = train_intensities.count(intensity)\n",
    "#             print(f\"    Intensity {intensity}: {count} samples\")\n",
    "            \n",
    "#         # Print example for each intensity level\n",
    "#         print(\"\\n  Examples by intensity:\")\n",
    "#         train_data = formatted_data[emotion]['train']\n",
    "#         for intensity in sorted(set(train_intensities)):\n",
    "#             idx = train_intensities.index(intensity)\n",
    "#             print(f\"    Intensity {intensity}: {train_data['data'][idx][:100]}...\")\n",
    "\n",
    "# format of formatted_data\n",
    "# {\n",
    "#     \"joy\": {\n",
    "#         \"train\": {\n",
    "#             \"data\": [\"text1\", \"text2\", ...],\n",
    "#             \"scenarios\": [\"scenario1\", \"scenario2\", ...],\n",
    "#             \"intensities\": [1, 2, ...]\n",
    "#         },\n",
    "#         \"test\": {\n",
    "#             \"data\": [\"text1\", \"text2\", ...],\n",
    "#             \"scenarios\": [\"scenario1\", \"scenario2\", ...],\n",
    "#             \"intensities\": [1, 2, ...]\n",
    "#         }\n",
    "#     },\n",
    "#     ...\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM \n",
    "import torch\n",
    "\n",
    "def setup_model_and_tokenizer(model_name=\"EleutherAI/gpt-neo-1.3B\"):\n",
    "    \"\"\"\n",
    "    Setup the model and tokenizer\n",
    "    \"\"\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    ).eval()\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        use_fast=True,\n",
    "        padding_side=\"left\",\n",
    "        legacy=False\n",
    "    )\n",
    "    \n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token_id = 0\n",
    "    tokenizer.bos_token_id = 1\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from typing import List, Dict, Optional, Union\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepReader:\n",
    "    def __init__(self, model, tokenizer, hidden_layers):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.directions = {}\n",
    "        self.direction_signs = {}\n",
    "        self.emotion_centroids = {}  # Store emotion centroids for each intensity level\n",
    "        self.max_length = 512\n",
    "\n",
    "    def get_hidden_states(self, text: str, padding_length: int = None) -> Dict[int, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Get hidden states for all specified layers with consistent padding\n",
    "        \"\"\"\n",
    "        pad_length = padding_length if padding_length is not None else self.max_length\n",
    "        \n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=pad_length\n",
    "        ).to(self.model.device)\n",
    "        \n",
    "        hidden_states = {layer: [] for layer in self.hidden_layers}\n",
    "        \n",
    "        def hook_fn(module, input, output, layer_id):\n",
    "            hidden_states[layer_id] = output[0].detach()\n",
    "        \n",
    "        hooks = []\n",
    "        for layer_id in self.hidden_layers:\n",
    "            layer = self.model.transformer.h[abs(layer_id)]\n",
    "            hook = layer.register_forward_hook(\n",
    "                lambda mod, inp, out, layer_id=layer_id: hook_fn(mod, inp, out, layer_id)\n",
    "            )\n",
    "            hooks.append(hook)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.model(**inputs)\n",
    "        \n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "        \n",
    "        return hidden_states\n",
    "\n",
    "    def get_directions(self, texts: List[str], intensities: List[int], emotion: str) -> Dict[int, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Get emotion direction vectors using intensity-aware approach\n",
    "        \"\"\"\n",
    "        # First determine the maximum sequence length needed\n",
    "        max_seq_length = 0\n",
    "        for text in texts:\n",
    "            tokens = self.tokenizer(text, truncation=True, max_length=self.max_length)\n",
    "            max_seq_length = max(max_seq_length, len(tokens['input_ids']))\n",
    "\n",
    "        # Get hidden states for all texts\n",
    "        all_hidden_states = []\n",
    "        for text in texts:\n",
    "            try:\n",
    "                states = self.get_hidden_states(text, padding_length=max_seq_length)\n",
    "                all_hidden_states.append(states)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing text: {text[:50]}...\")\n",
    "                print(f\"Error: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        if not all_hidden_states:\n",
    "            print(\"No valid hidden states were generated.\")\n",
    "            return self.directions\n",
    "\n",
    "        # Initialize storage for intensity-specific centroids\n",
    "        if emotion not in self.emotion_centroids:\n",
    "            self.emotion_centroids[emotion] = {}\n",
    "\n",
    "        # Calculate directions for each layer\n",
    "        for layer in self.hidden_layers:\n",
    "            try:\n",
    "                # Stack hidden states\n",
    "                layer_states = torch.stack([states[layer] for states in all_hidden_states])\n",
    "                \n",
    "                # Average across sequence length dimension\n",
    "                layer_states = layer_states.mean(dim=2)  # [batch_size, hidden_dim]\n",
    "                \n",
    "                # Move to CPU for processing\n",
    "                layer_states_cpu = layer_states.cpu()\n",
    "                intensities_tensor = torch.tensor(intensities).cpu()\n",
    "                \n",
    "                # Calculate centroids for each intensity level\n",
    "                unique_intensities = torch.unique(intensities_tensor)\n",
    "                intensity_centroids = {}\n",
    "                \n",
    "                for intensity in unique_intensities:\n",
    "                    mask = intensities_tensor == intensity\n",
    "                    if mask.any():\n",
    "                        centroid = layer_states_cpu[mask].mean(dim=0)\n",
    "                        intensity_centroids[int(intensity.item())] = centroid\n",
    "\n",
    "                # Calculate direction as the vector between lowest and highest intensity\n",
    "                min_intensity = min(intensity_centroids.keys())\n",
    "                max_intensity = max(intensity_centroids.keys())\n",
    "                \n",
    "                direction = intensity_centroids[max_intensity] - intensity_centroids[min_intensity]\n",
    "                direction = direction.squeeze()  # Ensure direction is 1D\n",
    "                direction = direction / torch.norm(direction)\n",
    "                \n",
    "                # Store the direction and centroids\n",
    "                self.directions[layer] = direction.to(self.model.device)\n",
    "                self.direction_signs[layer] = torch.tensor(1.0).to(self.model.device)\n",
    "                \n",
    "                if layer not in self.emotion_centroids[emotion]:\n",
    "                    self.emotion_centroids[emotion][layer] = {}\n",
    "                self.emotion_centroids[emotion][layer].update({\n",
    "                    k: v.to(self.model.device) \n",
    "                    for k, v in intensity_centroids.items()\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing layer {layer}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        return self.directions\n",
    "\n",
    "    def get_emotion_scores(self, text: str, emotion: str = None, target_intensity: int = None) -> Dict[int, float]:\n",
    "        \"\"\"\n",
    "        Get emotion scores for each layer, optionally comparing to a specific intensity level\n",
    "        \"\"\"\n",
    "        states = self.get_hidden_states(text)\n",
    "        scores = {}\n",
    "        \n",
    "        for layer in self.hidden_layers:\n",
    "            if layer in self.directions and emotion in self.emotion_centroids:\n",
    "                # Average across sequence length\n",
    "                avg_states = states[layer].mean(dim=1).reshape(-1)\n",
    "                \n",
    "                if target_intensity is not None and target_intensity in self.emotion_centroids[emotion][layer]:\n",
    "                    # Compare to specific intensity centroid\n",
    "                    centroid = self.emotion_centroids[emotion][layer][target_intensity]\n",
    "                    score = F.cosine_similarity(\n",
    "                        avg_states.unsqueeze(0),\n",
    "                        centroid.unsqueeze(0)\n",
    "                    )\n",
    "                else:\n",
    "                    # Use direction-based scoring\n",
    "                    score = torch.matmul(avg_states, self.directions[layer])\n",
    "                \n",
    "                scores[layer] = float(score * self.direction_signs[layer])\n",
    "        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepController:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        rep_reader,\n",
    "        max_modification: float = 2.0,\n",
    "        base_scale_factor: float = 1.5\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.rep_reader = rep_reader\n",
    "        self.max_modification = max_modification\n",
    "        self.base_scale_factor = base_scale_factor\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "        # Set pad_token_id if it's None\n",
    "        if self.tokenizer.pad_token_id is None:\n",
    "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
    "\n",
    "    def get_layer_scale(self, layer_id: int) -> float:\n",
    "        \"\"\"\n",
    "        Calculate layer-specific scaling factor.\n",
    "        Deeper layers get less modification.\n",
    "        \n",
    "        Args:\n",
    "            layer_id: The ID of the layer\n",
    "            \n",
    "        Returns:\n",
    "            float: Scaling factor for the layer\n",
    "        \"\"\"\n",
    "        layer_depth = abs(layer_id)\n",
    "        total_layers = len(self.rep_reader.hidden_layers)\n",
    "        \n",
    "        # Exponential decay for layer scaling\n",
    "        scale = np.exp(-layer_depth / (total_layers / 2))\n",
    "        return scale\n",
    "\n",
    "    def create_emotion_hook(\n",
    "        self,\n",
    "        emotion: str,\n",
    "        scale_factor: float,\n",
    "        target_intensity: Optional[int] = None\n",
    "    ):\n",
    "        def hook_fn(module, input_tensor, output):\n",
    "            try:\n",
    "                layer_id = self.rep_reader.hidden_layers[0]\n",
    "                if layer_id not in self.rep_reader.directions or emotion not in self.rep_reader.emotion_centroids:\n",
    "                    return output\n",
    "\n",
    "                hidden_states = output[0]\n",
    "                batch_size, seq_length, hidden_dim = hidden_states.size()\n",
    "\n",
    "                # Get layer-specific scaling\n",
    "                layer_scale = self.get_layer_scale(layer_id)\n",
    "                \n",
    "                # Get direction and calculate emotion component\n",
    "                direction = self.rep_reader.directions[layer_id]\n",
    "                emotion_component = direction.unsqueeze(0) * scale_factor * layer_scale\n",
    "\n",
    "                # Apply gradient clipping\n",
    "                emotion_component = torch.clamp(\n",
    "                    emotion_component,\n",
    "                    min=-self.max_modification,\n",
    "                    max=self.max_modification\n",
    "                )\n",
    "\n",
    "                # Reshape for broadcasting\n",
    "                emotion_component = emotion_component.unsqueeze(1).expand(-1, seq_length, -1)\n",
    "                \n",
    "                # Apply modification\n",
    "                modified_states = hidden_states + emotion_component\n",
    "                \n",
    "                return (modified_states,) + output[1:]\n",
    "\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error in emotion hook: {str(e)}\")\n",
    "                return output\n",
    "\n",
    "        return hook_fn\n",
    "\n",
    "    def generate_with_emotion(\n",
    "        self,\n",
    "        text: str,\n",
    "        emotion: str,\n",
    "        intensity: float = 5.0,\n",
    "        max_new_tokens: int = 50,\n",
    "        num_return_sequences: int = 1,\n",
    "        temperature: float = 0.7,\n",
    "        **kwargs\n",
    "    ) -> List[str]:\n",
    "        # Format prompt\n",
    "        prompt = f\"Express {emotion} with a single concise response to: {text}\\nResponse:\"\n",
    "        # prompt = f\"Rephrase '{text}' to express {emotion} in a single concise sentence \\nSentence:\"\n",
    "\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        # Calculate scale factor\n",
    "        scale_factor = (intensity / 10.0) * self.base_scale_factor\n",
    "\n",
    "        # Register hooks\n",
    "        hooks = []\n",
    "        for layer_id in self.rep_reader.hidden_layers[:3]:  # Only use top 3 layers\n",
    "            layer = self.model.transformer.h[abs(layer_id)]\n",
    "            hook = layer.register_forward_hook(\n",
    "                self.create_emotion_hook(emotion, scale_factor, None)\n",
    "            )\n",
    "            hooks.append(hook)\n",
    "\n",
    "        try:\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                num_return_sequences=num_return_sequences,\n",
    "                do_sample=True,\n",
    "                temperature=temperature,\n",
    "                top_k=30,\n",
    "                top_p=0.85,\n",
    "                no_repeat_ngram_size=3,\n",
    "                repetition_penalty=1.3,\n",
    "                pad_token_id=self.tokenizer.pad_token_id,\n",
    "                **kwargs\n",
    "            )\n",
    "\n",
    "            # Process outputs\n",
    "            generated_texts = []\n",
    "            for output in outputs:\n",
    "                text = self.tokenizer.decode(output[inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "                text = re.sub(r'([.,!?])\\1+', r'\\1', text)  # Clean up repeated punctuation\n",
    "                text = re.sub(r'\\s+', ' ', text).strip()    # Clean up whitespace\n",
    "                generated_texts.append(text)\n",
    "\n",
    "            return generated_texts\n",
    "\n",
    "        finally:\n",
    "            for hook in hooks:\n",
    "                hook.remove()\n",
    "\n",
    "    def transfer_emotion(\n",
    "        self,\n",
    "        text: str,\n",
    "        source_emotion: str,\n",
    "        target_emotion: str,\n",
    "        target_intensity: float = 5.0,\n",
    "        **kwargs\n",
    "    ) -> str:\n",
    "        # Generate with low intensity first\n",
    "        neutral_text = self.generate_with_emotion(\n",
    "            text=text,\n",
    "            emotion=source_emotion,\n",
    "            intensity=0.1,\n",
    "            temperature=0.3,\n",
    "            **kwargs\n",
    "        )[0]\n",
    "\n",
    "        # Then apply target emotion\n",
    "        final_text = self.generate_with_emotion(\n",
    "            text=neutral_text,\n",
    "            emotion=target_emotion,\n",
    "            intensity=target_intensity,\n",
    "            temperature=0.5,\n",
    "            **kwargs\n",
    "        )[0]\n",
    "\n",
    "        return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and prepare data with the new prepare_emotion_dataset\n",
    "formatted_data = prepare_emotion_dataset(\"combined_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pre-trained model\n",
    "model, tokenizer = setup_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize and train the new intensity-aware RepReader\n",
    "hidden_layers = list(range(-1, -model.config.num_hidden_layers, -1))\n",
    "rep_reader = RepReader(model, tokenizer, hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in formatted_data:\n",
    "    texts = formatted_data[emotion]['train']['data']\n",
    "    intensities = formatted_data[emotion]['train']['intensities']\n",
    "    rep_reader.get_directions(texts, intensities, emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup RepController\n",
    "controller = RepController(model, tokenizer, rep_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I’m happy, I‘m happy It’s a good feeling to be happy, isn’t it? You’re not alone. I”m happy too. The happiness']\n"
     ]
    }
   ],
   "source": [
    "result = controller.generate_with_emotion(\n",
    "    text=\"I am happy\",\n",
    "    emotion=\"joy\",\n",
    "    intensity=7.0,\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry. Please forgive me. I am so sorry for being upset. Please don't be upset. I'm sorry that I'm upset. You can tell me if you want. I'll try to be more understanding. I have\n"
     ]
    }
   ],
   "source": [
    "transferred = controller.transfer_emotion(\n",
    "    text=\"I feel terrible\",\n",
    "    source_emotion=\"joy\",\n",
    "    target_emotion=\"sadness\",\n",
    "    target_intensity=6.0\n",
    ")\n",
    "print(transferred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
